{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Early instability metrics (heuristic)\n",
        "\n",
        "This notebook computes a few **instability-oriented metrics** on JSONL traces:\n",
        "\n",
        "- relative latency gaps between consecutive events,\n",
        "- recovery turn distance (from first `drift_like` to `stability_tag='recovered'`),\n",
        "- post-correction relapse rate,\n",
        "- a simple session closure profile.\n",
        "\n",
        "It mirrors the logic of `scripts/compute_metrics_from_jsonl.py`, but is\n",
        "kept inline here for interactive exploration.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import json\n",
        "import statistics\n",
        "from collections import Counter, defaultdict\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "from typing import Any, Dict, Iterable, List, Optional, Tuple\n",
        "\n",
        "DATA_DIR = Path(\"examples\") / \"synthetic_traces\"\n",
        "print(f\"Using synthetic traces from: {DATA_DIR.resolve()}\")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "@dataclass\n",
        "class Event:\n",
        "    raw: Dict[str, Any]\n",
        "\n",
        "    @property\n",
        "    def trace_id(self) -> str:\n",
        "        return str(self.raw.get(\"trace_id\", \"\"))\n",
        "\n",
        "    @property\n",
        "    def event_type(self) -> str:\n",
        "        return str(self.raw.get(\"event_type\", \"\"))\n",
        "\n",
        "    @property\n",
        "    def component(self) -> str:\n",
        "        return str(self.raw.get(\"component\", \"\"))\n",
        "\n",
        "    @property\n",
        "    def payload(self) -> Dict[str, Any]:\n",
        "        obj = self.raw.get(\"payload\")\n",
        "        return obj if isinstance(obj, dict) else {}\n",
        "\n",
        "    @property\n",
        "    def latency_ms(self) -> Optional[float]:\n",
        "        val = self.payload.get(\"latency_ms\")\n",
        "        try:\n",
        "            return float(val) if val is not None else None\n",
        "        except (TypeError, ValueError):\n",
        "            return None\n",
        "\n",
        "    @property\n",
        "    def turn(self) -> Optional[int]:\n",
        "        val = self.payload.get(\"turn\") or self.raw.get(\"turn\")\n",
        "        try:\n",
        "            return int(val) if val is not None else None\n",
        "        except (TypeError, ValueError):\n",
        "            return None\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def load_events(path: Path) -> List[Event]:\n",
        "    events: List[Event] = []\n",
        "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            try:\n",
        "                obj = json.loads(line)\n",
        "            except json.JSONDecodeError:\n",
        "                continue\n",
        "            events.append(Event(obj))\n",
        "    return events\n",
        "\n",
        "def group_by_trace(events: Iterable[Event]) -> Dict[str, List[Event]]:\n",
        "    grouped: Dict[str, List[Event]] = defaultdict(list)\n",
        "    for ev in events:\n",
        "        grouped[ev.trace_id].append(ev)\n",
        "    return grouped\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def compute_relative_latency_gaps(traces: Dict[str, List[Event]]) -> List[float]:\n",
        "    gaps: List[float] = []\n",
        "    for events in traces.values():\n",
        "        prev: Optional[float] = None\n",
        "        for ev in events:\n",
        "            lat = ev.latency_ms\n",
        "            if lat is None:\n",
        "                continue\n",
        "            if prev is not None:\n",
        "                denom = max(prev, lat, 1.0)\n",
        "                gaps.append(abs(prev - lat) / denom)\n",
        "            prev = lat\n",
        "    return gaps\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def compute_recovery_turn_distances(traces: Dict[str, List[Event]]) -> List[int]:\n",
        "    distances: List[int] = []\n",
        "    for events in traces.values():\n",
        "        onset_turn: Optional[int] = None\n",
        "        for ev in events:\n",
        "            if onset_turn is None and ev.event_type == \"drift_like\":\n",
        "                onset_turn = ev.turn if ev.turn is not None else 0\n",
        "                continue\n",
        "            if onset_turn is not None:\n",
        "                tag = ev.payload.get(\"stability_tag\")\n",
        "                if tag == \"recovered\":\n",
        "                    end_turn = ev.turn if ev.turn is not None else onset_turn\n",
        "                    distances.append(max(0, end_turn - onset_turn))\n",
        "                    onset_turn = None\n",
        "    return distances\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def compute_post_correction_relapse_rate(traces: Dict[str, List[Event]]):\n",
        "    with_correction = 0\n",
        "    with_relapse = 0\n",
        "    for events in traces.values():\n",
        "        had_correction = False\n",
        "        relapsed = False\n",
        "        for ev in events:\n",
        "            if not had_correction and ev.event_type in {\"correction\", \"self_check\"}:\n",
        "                had_correction = True\n",
        "                continue\n",
        "            if had_correction and ev.event_type == \"drift_like\":\n",
        "                relapsed = True\n",
        "                break\n",
        "        if had_correction:\n",
        "            with_correction += 1\n",
        "            if relapsed:\n",
        "                with_relapse += 1\n",
        "    return with_relapse, with_correction\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "CLOSURE_LABELS = {\n",
        "    \"ok\": \"natural_completion\",\n",
        "    \"completed_after_correction\": \"completed_after_correction\",\n",
        "    \"corrected\": \"completed_after_correction\",\n",
        "    \"incomplete\": \"incomplete\",\n",
        "    \"error\": \"forced_stop\",\n",
        "}\n",
        "\n",
        "def classify_session_closure(events: List[Event]) -> str:\n",
        "    if not events:\n",
        "        return \"unknown\"\n",
        "    last = events[-1]\n",
        "    payload = last.payload\n",
        "    status = str(payload.get(\"status\", \"\")).strip()\n",
        "    final_status = str(payload.get(\"final_status\", \"\")).strip()\n",
        "    pattern = str(payload.get(\"pattern\", \"\")).strip()\n",
        "    for key in (status or None, final_status or None, pattern or None):\n",
        "        if not key:\n",
        "            continue\n",
        "        label = CLOSURE_LABELS.get(key)\n",
        "        if label:\n",
        "            return label\n",
        "    if last.event_type == \"session_end\":\n",
        "        return \"session_end_generic\"\n",
        "    if last.component == \"user\":\n",
        "        return \"user_abandonment\"\n",
        "    return \"unknown\"\n",
        "\n",
        "def compute_session_closure_profile(traces: Dict[str, List[Event]]) -> Counter:\n",
        "    counts: Counter = Counter()\n",
        "    for events in traces.values():\n",
        "        label = classify_session_closure(events)\n",
        "        counts[label] += 1\n",
        "    return counts\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def summarize_file(path: Path):\n",
        "    events = load_events(path)\n",
        "    traces = group_by_trace(events)\n",
        "    print(f\"\\n=== {path} ===\")\n",
        "    print(f\"events : {len(events)}\")\n",
        "    print(f\"sessions: {len(traces)}\\n\")\n",
        "\n",
        "    gaps = compute_relative_latency_gaps(traces)\n",
        "    if gaps:\n",
        "        print(\"[relative-latency-gap]\")\n",
        "        print(f\"  samples: {len(gaps)}\")\n",
        "        print(f\"  mean   : {statistics.mean(gaps):.3f}\")\n",
        "        print(f\"  median : {statistics.median(gaps):.3f}\")\n",
        "        print()\n",
        "\n",
        "    rtd = compute_recovery_turn_distances(traces)\n",
        "    if rtd:\n",
        "        print(\"[recovery-turn-distance]\")\n",
        "        print(f\"  episodes: {len(rtd)}\")\n",
        "        print(f\"  mean    : {statistics.mean(rtd):.2f} turns\")\n",
        "        print(f\"  median  : {statistics.median(rtd):.2f} turns\")\n",
        "        print()\n",
        "\n",
        "    relapsed, corrected = compute_post_correction_relapse_rate(traces)\n",
        "    if corrected:\n",
        "        rate = (relapsed / corrected) * 100\n",
        "        print(\"[post-correction-relapse-rate]\")\n",
        "        print(f\"  sessions with correction: {corrected}\")\n",
        "        print(f\"  sessions with relapse   : {relapsed}\")\n",
        "        print(f\"  relapse rate            : {rate:.1f}%\")\n",
        "        print()\n",
        "\n",
        "    profile = compute_session_closure_profile(traces)\n",
        "    if profile:\n",
        "        print(\"[session-closure-profile]\")\n",
        "        total = sum(profile.values())\n",
        "        for label, count in profile.most_common():\n",
        "            pct = (count / total) * 100\n",
        "            print(f\"  {label:28s}: {count:3d}  ({pct:4.1f}%)\")\n",
        "        print()\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Run on the bundled synthetic traces\n",
        "for name in [\"simple_correction_loop.jsonl\", \"noisy_mixed_sessions.jsonl\"]:\n",
        "    path = DATA_DIR / name\n",
        "    summarize_file(path)\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}